{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing Workflow:\n",
    "\n",
    "This notebook is being used to hanlde the preprocessing portion of the capstone. The intent is to help me work through to a final construct for a presentation and deliverable for the final capstone at Thinkful. It is not a submission. \n",
    "\n",
    "\n",
    "*premise:*\n",
    "\n",
    "The capstone is from the [Kaggle TalkingData](https://www.kaggle.com/c/talkingdata-mobile-user-demographics/overview) dataset. The product is a demographic identifier. Using information retreived from an electronic device, such as a cell phone; tablet; netbook; etc. - the tool reviews the applications users have installed, the type of applications, etc. to determine the age and gender of the users. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A summary of missing variables represented as a percentage of the total missing content. \n",
    "def null_summary(df, print_log=False, sort='ascending'):\n",
    "    s = df.isnull().sum()*100/df.isnull().count()\n",
    "    \n",
    "    if sort.lower() == 'ascending':\n",
    "        s = s.sort_values(ascending=True)\n",
    "    elif sort.lower() == 'descending':\n",
    "        s = s.sort_values(ascending=False)  \n",
    "    if print_log: \n",
    "        print('Percentage of null values: \\n', s)\n",
    "  \n",
    "    return pd.Series(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data available on Kaggle is split into several different CSV files. Extract the files and review the data. What is the resulting dataframe going to look like? What can be changed, altered, updated, used, to predict the target variables?\n",
    "\n",
    "What are the target variables? etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APP_EVENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_events = pd.read_csv('./data/app_events.csv.zip', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>app_id</th>\n",
       "      <th>is_installed</th>\n",
       "      <th>is_active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>5927333115845830913</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-5720078949152207372</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-1633887856876571208</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>-653184325010919369</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>8693964245073640147</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_id               app_id  is_installed  is_active\n",
       "0         2  5927333115845830913             1          1\n",
       "1         2 -5720078949152207372             1          0\n",
       "2         2 -1633887856876571208             1          0\n",
       "3         2  -653184325010919369             1          1\n",
       "4         2  8693964245073640147             1          1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "event_id        1488096\n",
       "app_id            19237\n",
       "is_installed          1\n",
       "is_active             2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Can an app be active if it is not installed?\n",
    "app_events.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "event_id        0.0\n",
       "app_id          0.0\n",
       "is_installed    0.0\n",
       "is_active       0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_summary(app_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions and observations\n",
    "\n",
    "It looks like is_installed is an unnecessary column. I will not want to use this column in my analysis or usage are there are no applications that do not have an application. The assumption is that I'm going to encode categorical variables so that they're ready for use with machine learning; so situations where an app is not installed will be labeled with a 1 or 0 on the column interval. This justifies the loss of the is_installed column. \n",
    "\n",
    "is_active is a binary type. \n",
    "\n",
    "Do people who have a certain number of active applications fall within a certain age group?\n",
    "Are people who identify as male or female more likely to have more application installed? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "events =  pd.read_csv('./data/events.csv.zip', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>device_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>29182687948017175</td>\n",
       "      <td>2016-05-01 00:55:25</td>\n",
       "      <td>121.38</td>\n",
       "      <td>31.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-6401643145415154744</td>\n",
       "      <td>2016-05-01 00:54:12</td>\n",
       "      <td>103.65</td>\n",
       "      <td>30.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-4833982096941402721</td>\n",
       "      <td>2016-05-01 00:08:05</td>\n",
       "      <td>106.60</td>\n",
       "      <td>29.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-6815121365017318426</td>\n",
       "      <td>2016-05-01 00:06:40</td>\n",
       "      <td>104.27</td>\n",
       "      <td>23.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-5373797595892518570</td>\n",
       "      <td>2016-05-01 00:07:18</td>\n",
       "      <td>115.88</td>\n",
       "      <td>28.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_id            device_id            timestamp  longitude  latitude\n",
       "0         1    29182687948017175  2016-05-01 00:55:25     121.38     31.24\n",
       "1         2 -6401643145415154744  2016-05-01 00:54:12     103.65     30.97\n",
       "2         3 -4833982096941402721  2016-05-01 00:08:05     106.60     29.70\n",
       "3         4 -6815121365017318426  2016-05-01 00:06:40     104.27     23.28\n",
       "4         5 -5373797595892518570  2016-05-01 00:07:18     115.88     28.66"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "event_id     0.0\n",
       "device_id    0.0\n",
       "timestamp    0.0\n",
       "longitude    0.0\n",
       "latitude     0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_summary(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "event_id     3252950\n",
       "device_id      60865\n",
       "timestamp     588125\n",
       "longitude       3588\n",
       "latitude        3086\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "event_id       3252950\n",
       "device_id      3252950\n",
       "timestamp      3252950\n",
       "longitude      3252950\n",
       "latitude       3252950\n",
       "coordinates    3252950\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "events['coordinates'] = [(x, y) for x, y in zip(events.latitude, events.longitude)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30.28, 112.29)    9\n",
       "(36.71, 121.38)    9\n",
       "(31.3, 120.61)     9\n",
       "(23.19, 113.22)    9\n",
       "(32.01, 119.08)    9\n",
       "                  ..\n",
       "(30.28, 106.5)     1\n",
       "(34.55, 115.39)    1\n",
       "(32.18, 119.35)    1\n",
       "(22.61, 113.85)    1\n",
       "(25.81, 114.82)    1\n",
       "Name: coordinates, Length: 41282, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events['coordinates'].value_counts()[events['coordinates'].value_counts() < 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>device_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>805906</th>\n",
       "      <td>805907</td>\n",
       "      <td>5404477794074719040</td>\n",
       "      <td>2016-05-06 00:12:36</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(0.01, 0.23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2868208</th>\n",
       "      <td>2868209</td>\n",
       "      <td>5404477794074719040</td>\n",
       "      <td>2016-05-06 00:13:36</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(0.01, 0.23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805905</th>\n",
       "      <td>805906</td>\n",
       "      <td>5404477794074719040</td>\n",
       "      <td>2016-05-06 00:12:06</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(0.01, 0.23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3041067</th>\n",
       "      <td>3041068</td>\n",
       "      <td>5404477794074719040</td>\n",
       "      <td>2016-05-06 00:13:22</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(0.01, 0.23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028688</th>\n",
       "      <td>2028689</td>\n",
       "      <td>-1471692881227537768</td>\n",
       "      <td>2016-05-07 15:57:44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(0.01, 0.44)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2912133</th>\n",
       "      <td>2912134</td>\n",
       "      <td>-8587046306349220863</td>\n",
       "      <td>2016-05-06 14:08:17</td>\n",
       "      <td>124.71</td>\n",
       "      <td>52.33</td>\n",
       "      <td>(52.33, 124.71)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266877</th>\n",
       "      <td>2266878</td>\n",
       "      <td>-8587046306349220863</td>\n",
       "      <td>2016-05-06 14:21:29</td>\n",
       "      <td>124.71</td>\n",
       "      <td>52.33</td>\n",
       "      <td>(52.33, 124.71)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011467</th>\n",
       "      <td>1011468</td>\n",
       "      <td>7741178197893917209</td>\n",
       "      <td>2016-05-07 11:54:01</td>\n",
       "      <td>30.21</td>\n",
       "      <td>59.94</td>\n",
       "      <td>(59.94, 30.21)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251872</th>\n",
       "      <td>251873</td>\n",
       "      <td>7741178197893917209</td>\n",
       "      <td>2016-05-07 12:33:55</td>\n",
       "      <td>30.21</td>\n",
       "      <td>59.94</td>\n",
       "      <td>(59.94, 30.21)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510236</th>\n",
       "      <td>1510237</td>\n",
       "      <td>7741178197893917209</td>\n",
       "      <td>2016-05-07 13:58:47</td>\n",
       "      <td>30.21</td>\n",
       "      <td>59.94</td>\n",
       "      <td>(59.94, 30.21)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2282649 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         event_id            device_id            timestamp  longitude  \\\n",
       "805906     805907  5404477794074719040  2016-05-06 00:12:36       0.23   \n",
       "2868208   2868209  5404477794074719040  2016-05-06 00:13:36       0.23   \n",
       "805905     805906  5404477794074719040  2016-05-06 00:12:06       0.23   \n",
       "3041067   3041068  5404477794074719040  2016-05-06 00:13:22       0.23   \n",
       "2028688   2028689 -1471692881227537768  2016-05-07 15:57:44       0.44   \n",
       "...           ...                  ...                  ...        ...   \n",
       "2912133   2912134 -8587046306349220863  2016-05-06 14:08:17     124.71   \n",
       "2266877   2266878 -8587046306349220863  2016-05-06 14:21:29     124.71   \n",
       "1011467   1011468  7741178197893917209  2016-05-07 11:54:01      30.21   \n",
       "251872     251873  7741178197893917209  2016-05-07 12:33:55      30.21   \n",
       "1510236   1510237  7741178197893917209  2016-05-07 13:58:47      30.21   \n",
       "\n",
       "         latitude      coordinates  \n",
       "805906       0.01     (0.01, 0.23)  \n",
       "2868208      0.01     (0.01, 0.23)  \n",
       "805905       0.01     (0.01, 0.23)  \n",
       "3041067      0.01     (0.01, 0.23)  \n",
       "2028688      0.01     (0.01, 0.44)  \n",
       "...           ...              ...  \n",
       "2912133     52.33  (52.33, 124.71)  \n",
       "2266877     52.33  (52.33, 124.71)  \n",
       "1011467     59.94   (59.94, 30.21)  \n",
       "251872      59.94   (59.94, 30.21)  \n",
       "1510236     59.94   (59.94, 30.21)  \n",
       "\n",
       "[2282649 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events[(events.latitude > 0) & (events.longitude > 0)].sort_values(by=['coordinates'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the location and time of day have anything to do with the users demographics?\n",
    "\n",
    "Are certain users more likely to access the data in specific locations? How many users are 'hanging out' together? Perhaps they are all in the same demographic and are using the same apps. \n",
    "\n",
    "Or, depending on the app, they could be doing family things - perhaps there's a shared calendar involved that I will find is used at the same location by various genders and ages. They could be colleagues. I have to predict the ages and the gender. \n",
    "\n",
    "I'll want to look at the time of day based on the demographic and the location. For convenience, it may be worth having an extra cell with the location information stored as a tuple (I may want to map it).\n",
    "\n",
    "With over 900,000 datapoints at locations 0,0 and 1,1; I question whether or not it would be better to determine the user's demographic based on whether or not the user is GPS sharing. I will consider this as I move through and conduct my EDA. Because I have a 0.0 and a 1.1 and do not know what EITHER of those means - but some of these coordinates are in the ocean; so they could be on a boat and I've got a lot of them. \n",
    "\n",
    "One consideration is to do cluster analysis using an unsupervised learning method and a dissimilarity matrix to assign a categorical location on these coordinates. I may want to run a silhuoette score on this to determine the best number of clusters to use for these coordinates. I can identify categories after placing them on a map.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gender_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_train = pd.read_csv('./data/gender_age_train.csv.zip', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-8076087639492063270</td>\n",
       "      <td>M</td>\n",
       "      <td>35</td>\n",
       "      <td>M32-38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2897161552818060146</td>\n",
       "      <td>M</td>\n",
       "      <td>35</td>\n",
       "      <td>M32-38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8260683887967679142</td>\n",
       "      <td>M</td>\n",
       "      <td>35</td>\n",
       "      <td>M32-38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4938849341048082022</td>\n",
       "      <td>M</td>\n",
       "      <td>30</td>\n",
       "      <td>M29-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>245133531816851882</td>\n",
       "      <td>M</td>\n",
       "      <td>30</td>\n",
       "      <td>M29-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             device_id gender  age   group\n",
       "0 -8076087639492063270      M   35  M32-38\n",
       "1 -2897161552818060146      M   35  M32-38\n",
       "2 -8260683887967679142      M   35  M32-38\n",
       "3 -4938849341048082022      M   30  M29-31\n",
       "4   245133531816851882      M   30  M29-31"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device_id    74645\n",
       "gender       74645\n",
       "age          74645\n",
       "group        74645\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M23-26    9605\n",
       "M32-38    9476\n",
       "M39+      8581\n",
       "M22-      7488\n",
       "M29-31    7309\n",
       "F33-42    5561\n",
       "M27-28    5445\n",
       "F23-      5050\n",
       "F29-32    4628\n",
       "F43+      4194\n",
       "F24-26    4190\n",
       "F27-28    3118\n",
       "Name: group, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_train.group.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are my training variables. I want to concatenate these to the dataframe originally, so that I can perform the EDA; I'll split it back out later. \n",
    "\n",
    "What will a cluster analysis reveal about these groups?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gender_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_test = pd.read_csv('./data/gender_age_test.csv.zip', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186716"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_test.device_id.count() + gender_train.device_id.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [device_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#These devices are not in the training set, good! \n",
    "gender_test[gender_test.device_id.isin(gender_train.device_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1944822"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.device_id[events.device_id.isin(gender_test.device_id)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1308128"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify that this isn't in there. Oh. It is. \n",
    "events.device_id[~events.device_id.isin(gender_test.device_id)].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data that is associated with the test devices will need to be removed from the set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# label_categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_categories = pd.read_csv('./data/label_categories.csv.zip', compression='zip')\n",
    "#Afte reviewing the data, go ahead and fill the missing categories with the undefined label. \n",
    "label_categories.category.fillna('Undefined', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_id    930\n",
       "category    930\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_categories.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_id    930\n",
       "category    836\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_categories.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 26}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of value counts for all the categories. There are a lot of unique values. \n",
    "set(label_categories.category.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_id    3\n",
       "category    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_categories[label_categories.category == 'Undefined'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Undefined', 'game-game type', 'game-Game themes', 'game-Art Style', 'game-Leisure time', 'game-Cutting things', 'game-Finding fault', 'game-stress reliever', 'game-pet', 'game-Answer', 'game-Fishing', 'game-Music and Dance', 'game-Puzzle', 'game-Adventure puzzle', 'game-Parkour Racing', 'game-Parkour', 'game-Racing', 'game-Motorcycle', 'game-Rowing', 'game-aircraft', 'game-Gem Elimination', 'game-Box', 'game-gem', 'game-Lianliankan', 'game-Zuma', 'game-Bobble', 'game-Cartoon', 'game-Online game', 'game-Role -playing games', 'game-Competitive action', 'game-Tactics', 'game-card', 'game-Business simulation', 'game-Action Shooting', 'game-Horizontal version', 'game-shooting', 'game-3D', 'game-flight', 'game-tank', 'game-Snipe', 'poker and chess', 'poker game_doudizhu', 'chess', 'majiang', 'table game', 'Texas Poker', 'poker', 'Children puzzle game', 'Puzzle', 'Literacy Games', 'Intellectual development game', 'math', 'Guard tower defense game', 'checkpoints game', 'Beach landing game', 'fighting game', 'old style game', 'basketball', 'football', 'tennis', 'billards', 'other ball game', 'RPG game', 'Turn based RPG game', 'realtime fighting', 'ARPG', 'business strategy game', 'war chess', 'business', 'farm', 'raising up game', 'pet raising up', 'love raising up', 'unknown', 'puzzel', 'gambling', '3 kindom game', 'knight game', 'Cultivation fantasy game', 'Journey to the West game', 'Outlaws of the Marsh game', 'Chinese Classical Mythology', 'Western Mythology', '80s Japanese comic', '90s Japanese comic', 'movie', 'shows', 'millitary and wars', 'science fiction', 'zombies game', 'World of Warcraft', 'magic', 'dotal-lol', 'sailing game', 'sports', 'Chinese painting', 'japanese and korean style', 'japanese comic and animation', 'US and Europe animation', 'Cute style comic', 'pixel style comic', 'violence comic', 'US and Europe magic comic', 'realistic style comic', 'chinese comic', 'unknown', 'unknown', 'unknown', 'online shopping', 'online malls', 'online shopping by group, like groupon', 'online shopping navigation', 'online shopping, price comparing', 'shopping sharing', 'education', 'education for babies', 'education outside class', 'study abroad', 'foreign language', 'professional skills', 'management', 'art and culture', 'library', 'exams', 'dialects', 'class managemetn', 'reading', 'reading for fetus', 'children books', 'novels', 'magazine and journal', 'comics', 'dictionary', 'reading platform', 'poetry', 'joke', 'psychology', 'science', 'Information', 'news', 'Entertainment News', 'Academic Information', 'Sports News', 'Financial Information', 'Technology Information', 'gaming strategy', 'Socially', 'weibo', 'love and marriage', 'community', 'picture sharing', 'blogs', 'communitation', 'IM', 'mesasge', 'email', 'phone', 'movie', 'radio', 'music', 'video', 'show', 'Audiobooks', 'Business Travel', 'map', 'navigation', 'Behalf of the drive', 'Taxi', 'Car', 'flight', 'Bus', 'train', 'Hotel application', 'Travel advisory', 'tourism product', 'Share Travels', 'coach transport', 'Household', 'Decoration', 'Appliances', 'Furniture', 'household products', 'Smart Home', 'health', 'lose weight', 'sports and gym', 'health', 'Medical', 'Health Management', 'Living', 'pictures photography', 'Man playing favorites', 'takeaway ordering', 'Astrology Horoscope', 'coupon', 'Reviews', 'Recipes', 'Business Office', 'Weather', 'Clock', 'Express', 'Calendar', 'Accounting', 'Car Owners', 'convenience services', 'fashion outfit', 'Points Activities', 'Housekeeping', 'Integrated Living', 'work', 'Jobs', 'Scheduling', 'notes', 'notes', 'File Editor', 'business cards', 'Contacts', 'network disk', 'store management', 'Engineering Drawing', 'phone tools', 'System Tools', 'App Store', 'search', 'Input Method', 'Browser', 'Desktop Enhancements', 'readers', 'Utilities', 'Undefined', 'Editor', 'WIFI', 'Finance', 'Wealth Management', 'IMF', 'Direct Bank', 'Direct Insurance', 'Securities', 'futures', 'Exchange', 'Precious Metals', 'Crowdfunding financing', 'Lottery ticket', 'Pay', 'Debit and credit', 'Undefined', 'Estate', 'Housing Advice', 'Buy', 'Sellers', 'Rentals', 'Mother', 'Prepare pregnant pregnancy', 'Parenting', 'Maternal and child supplies', 'entertainment', 'KTV', 'show', 'the film', 'car', 'Automotive News', 'Sale of cars', 'A beauty care', 'Skin care applications', 'Beauty Nail', 'Make-up application', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'Consumer preferences', 'Consumer Goods', 'Consumer orientation', 'Brand Country', 'Occupational identity', 'College Students', 'unknown', 'unknown', 'unknown', 'Condition of the vehicles', 'Car', 'No Car', 'Jewelry Watches', 'branded watch', 'fashion brand', 'Switzerland', 'Dress shoes', 'Women', 'Shoes', \"Men's\", \"Men's Shoes\", 'France', 'Hong Kong', 'Japan', 'High-end brand', 'United States', 'Outdoor sport', 'Germany', 'underwear', 'Home Clothing', 'Volkswagen brand', 'Sweden', 'Accessories', 'Italy', 'Household utensils', 'bed linings', 'Kids', 'Sports Health', 'outdoor equipment', 'China Mainland', 'Bags', 'Lady bags', 'Taiwan', 'Baby Products', 'Baby Clothing', 'M package', 'wallet', 'Digital', 'camera', 'Culture and Education', 'Office Supplies', 'Jewelry, jewelry', 'Swimming Supplies', 'Canada', 'Phone', 'Digital Accessories', 'computer', 'Luxury brand', 'cosmetic', 'Fragrance oils', 'Feature Pack', 'Suitcase', 'Makeup', 'Skin Care', 'FOOD', 'Fast food meals', 'Day feed', 'Home Decoration', 'United Kingdom', 'Collection process', 'Korea', 'Austria', 'Spain', 'Household appliances', 'home appliances', 'Bathroom products', 'Pregnant mother supplies', 'Shoes', 'Norway', 'Western Dinner', 'Kitchen Appliances', 'Australia', 'Leisure and entertainment', \"Children's entertainment\", 'SPA', 'Water Coffee Bar', 'Domestic services', 'Nail Tattoos', 'Custom label', 'unknown', 'DS_P2P net loan', 'Location', 'Go places', 'High places', 'Four five-star hotel', 'Golf Club', 'ski facility', 'transportation hub', 'AIRPORT', 'Culture & Education', 'the University', 'High school', 'Tourist attractions', 'hospital', 'Portugal', 'Large household appliances', 'Baby food', 'Snacks Snacks', 'Retail stores', 'Tobacco row', 'Decoration materials', 'Fitness Equipment', 'Hotels', 'Singapore', 'Korean food', 'Lunch Dinner', 'Bread dessert', 'Thailand', 'Belgium', 'Shabu hot pot', 'buffet', 'groceries', 'Convenience Store', 'Pharmacy / medical devices / Health', 'Denmark', 'Greece', 'Furniture', 'Kitchenware', 'Collection shop', 'Baby Care', 'Netherlands', 'Stereo headphones', 'Baby bed', 'kids toys', 'Digital stores', 'Education and Training', 'Swim', 'wig', 'tableware', 'Latvia', 'Coffee water bar / teahouse', 'retail', 'Brazil', 'Malaysia', 'Baby Home Textiles', 'SPA / Health Center', 'Finland', 'Laundry / Leather Care / change clothes', 'Sports', 'cinema', 'Musical Instruments', 'Beauty salons', 'Supermarkets', 'Financial Planning Services', 'car services', 'Auto 4S shop', 'tea shop', 'Photographic prints', 'Cycling Sport', 'Wedding services', 'KTV service', 'Appliance stores', 'Philippines', 'Tea cups', 'Board games and entertainment', 'Games', 'Gym', 'Cleaning Products', 'Experience', 'Car decoration', 'Real Estate Property', 'Housing agency', 'Florist / Fruit Shop', 'Fishing Tackle', 'Electric Car', 'Personal Care', 'Swimming pool', 'Video City', 'Aftermarket decoration', 'Billiard room', 'Foot Bath', 'Wedding photography', 'Pet Services', 'Internet cafes', 'bank', 'Parental photography', 'pharmacy', 'Supermarket', 'teahouse', 'Car Rental', 'bookstore', 'Health Products', 'flower shop', 'Driving School', 'Games deep tags', 'Game willingness to pay', 'Game amount paid', 'Game Frequency', 'Game Installation', 'Active Games', 'High (had paid behavior)', 'Low (not over charge behavior)', 'payment 1', 'payment 2', 'payment 3', 'payment 4', 'payment 5', 'Ultra-high frequency (more than seven consecutive days game behavior)', 'High Frequency (seven consecutive days there are games behavior)', 'IF (there are three consecutive days game behavior)', 'Low Frequency (only recently have the game play a day)', 'High installation (over 7 games)', 'The installation (3-7 games)', 'Low installation (only 1-2 games)', 'Active high (nearly 30 days played 7 games)', 'Active in (nearly 30 days played 3-7 games)', 'Low active (nearly 30 days played 1-2 games)', 'car brand', 'Industry tag', 'Property Industry 1.0', 'quality', 'Customization', 'Trendy / cool', 'Simple', 'Reputation', 'Relatives', 'Irritation / Fun', 'natural', 'service', 'free', 'Enthusiasm', 'noble', 'Science and Technology', 'vitality', 'pursue', 'Smart Shopping', 'Personal Effectiveness', 'classical', 'comfortable', 'Total Cost', 'Teahouse', 'Toiletries', 'Leather Care', 'cinema', 'Musical instruments', 'Indian Express', 'Foot Massage', 'Experience / DIY', 'Medical', 'marry', 'beauty', 'Hairdressing', 'financial', 'Slim', 'Paternity', 'Nail', 'Beauty SPA', 'Early Learning', 'medical instruments', 'Training institutions', 'Exam training', 'Device Properties', 'Brands', 'Equipment category', 'Phone', 'flat', 'Smart TV', 'smart watch', 'Smart bracelet', 'Features', 'Music phone', 'Beauty phone', 'Old machine', 'Photography phone', 'High-end business phone', 'Cost-effective mobile', 'screen size', '6.0 inches above', '6.0-5.6 inches', '5.5-5.1 inches', '5.0-4.6 inches', '4.5-3.1 inches', '3 inches and below', 'operating system', 'iOS', 'WP', 'Android', 'Hardware Features', '8-core chips', 'Gyro', 'NFC chip', 'Dual SIM', 'Operators', 'operatior 1', 'operator 2', 'operator 3', 'The internet', 'WIFI', '4G', '3G', '2G', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'shopping center', 'language training', 'Car Accessories', 'pawn shop', 'Bath', 'Express Inn', 'CAR WASH', 'General merchandise', 'Real Estate Agents', 'securities company', 'post Office', 'SCHOOL', 'the University', 'dance', 'Parenting', 'Month Center', 'Museum of Traditional Chinese Medicine', 'Corporate', 'Telecom company', 'Travel', \"Parent-child's play\", 'Personalized photo', 'Optical Shop', 'Star Hotels', 'Express', 'Logistics companies', 'Skills Training', 'Concert hall', 'Food company', 'Insurance company', 'car repair', 'fingerprint', 'City resident', 'family', 'model', 'Other operators', 'Ping', 'safety Insurance', 'Peace - Search', 'mobile bank', 'Insurance', 'Resolution', 'Wearable Health', 'Smart Appliances', 'Intelligent hardware', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'Property Industry 2.0', 'Quality 1', 'Customized 1', 'Trendy / cool 1', 'Simple 1', '1 reputation', 'Relatives 1', 'Irritation / Fun 1', 'Nature 1', 'Services 1', '1 free', 'Passion 1', 'Noble 1', 'Science and Technology 1', '1 vitality', 'Pursuit 1', 'Smart Shopping 1', 'Personal Effectiveness 1', 'Classical 1', 'Cozy 1', 'Total Cost 1', 'And the Church', 'stock', 'A shares', 'B Shares', 'H shares', 'N shares', 'Other shares', 'fund', 'Monetary Fund', 'Mixed Fund', 'Bond Fund', 'Capital Preservation Fund', 'QDII fund', 'Commodity Funds', 'Equity Fund', 'Index Fund', 'Closed-end funds', 'Insurance', 'Life Insurance', 'Insurance', 'Liability', 'Bank financing', 'fixed income', 'Guaranteed income', 'Non-guaranteed income', 'Consumer loans', 'Internet banking', 'P2P', 'Direct Banking', 'Third party payment', 'Crowdfunding', 'Financial Services', 'Trust', 'Trust funds', 'Chattel trust', 'Real Estate Trust', 'Property Trust', 'Intellectual Property Trust', 'Stock Futures', 'Commodity Futures', 'Financial Futures', 'High Flow', 'High mobility', 'Liquid medium', 'Lower liquidity', 'Low liquidity', 'High profitability', 'Higher income', 'Moderate profitability', 'Low profitability', 'Low income', 'High risk', 'Higher risk', 'Medium risk', 'Low risk', 'Low Risk', 'Financial Supermarket', 'other', 'Financial Information', 'Lottery ticket', 'exchange rate', 'Antique collection', 'Tencent', 'game', 'Cards RPG', 'MMO', 'round', 'ARPG', 'MOBA', 'SLG (strategy)', 'Racing (RAC)', 'Flight Shooting', 'Shootout Shooting (STG)', 'music', 'Sports', 'Tower Defense', 'Business simulation', 'Casual puzzle categories', 'Chess categories', 'Parkour avoid class', 'The elimination of class', 'Animation', 'Animation aggregate class', 'Class animation community', 'Comics Reading Tools', 'literature', \"Read the operator's\", 'read', 'Pirated content', 'Listening to books category', 'Other Read', 'Hardware Related', 'the film', 'Online booking class', 'User Community', 'Vermicelli', 'Buy class', 'Pay', 'Not paid the fee', 'paid1', 'paid2', 'paid3', 'paid4', 'paid5', 'paid6', 'paid7', 'Doctors', 'Maternal and child population', 'Prepare baby', 'Families with babies', 'Pregnant baby', 'Parenting stage', 'Families with big baby', 'Families with small babies', 'Sea Amoy', 'He slightly - Family Life Cycle', 'Youth House', 'the little sun', 'Three Generations of children', 'Middle-aged home', 'Empty nesters', 'Property Industry new', 'noble', 'Total Cost', 'free', 'natural', 'pursue', 'quality', 'Cool trendy', 'Relatives', 'Smart Shopping', 'Reputation', 'Science and Technology', 'Simple', 'Enthusiasm', 'vitality', 'classical', 'Personal Effectiveness', 'service', 'Customization', 'Stimulate fun', 'comfortable', 'Viewing preferences', 'physical education', 'health', 'Public class', 'military', 'Animation', 'Original', 'Wonderful', 'Olympic', 'entertainment', 'Children', 'advertising', 'microfilm', 'Funny', 'education', 'tourism', 'Fashion Arts', 'fashion', 'Mother', 'car', 'game', 'Trailer', 'life', 'the film', 'TV series', 'Science and Technology', 'Documentary', 'Arts', 'Lenovo Cooperation', 'Talk show', 'Finance and economics', 'Information', 'music', 'other', 'Air Travel', 'aviation', 'Airline type', 'Full Service Airlines', 'Low Cost Airlines', 'Regional Aviation', 'High-end business aviation', 'General Aviation', 'Aviation Integrated Services', 'Aeronautical Information Service', 'Airline Alliances', 'airport', 'Flight area', 'Chinese mainland (Airlines)', 'Southeast Asia (aviation)', 'Japan and South Korea (Air)', 'Europe, the United States and Macao (aviation)', 'Hong Kong, Macao and Taiwan (aviation)', 'travel', 'Purpose of travel', 'Travel Travel', 'Overseas travel', 'Domestic travel', 'Integrated tourism', 'Tour around', 'Travel Information', 'Free exercise', 'Travel preferences', 'Share Tour', 'Destination Region', 'Southeast Asia (Travel)', 'Japan and South Korea (Travel)', 'Europe, the United States and Macao (Travel)', 'Hong Kong, Macao and Taiwan (Travel)', 'Booking channels', 'Integrated ticket reservation', 'Book hotel complex', 'High-speed rail train reservation', 'Coach reservations', 'Integrated Air Travel Booking', 'Hotels', 'Hotel Type', 'High-end hotel', 'Hotel Chain', 'Non-standard accommodation', 'financial', 'P2P', 'unknown', 'BM', 'NS', 'Card Game', 'casual games', 'Puzzles', 'cosplay', 'Sports Games', 'Table Games', 'action games', 'strategy game', 'Simulators', 'Adventure Game', 'Chess game', 'Dice Game', 'Educational games', 'Family Games', 'Music Games', 'Racing games', 'Games', 'Word games', 'Xian Xia', 'effort', 'navigation', 'Tomb', 'reality show', 'Jin Yong', 'trickery', 'Senki', 'Journey', 'tribe', 'Ninja', 'Romance', 'Shushan', 'Martial arts', 'Domestic animation', 'Europe and Fantasy', 'Harem', 'fashion', 'Finance', 'Traditional securities brokerage', 'Lottery ticket', 'P2P net loan', 'Pay', 'Crowdfunding', 'Accounting', 'Third-party card management', 'Internet Banking', 'Financial Information', 'Consumer Finance', 'mobile bank', 'Traditional Insurance', 'Heritage Foundation', 'Direct Banking', 'Internet Securities', 'Bank Credit Card', 'Internet Insurance']\n"
     ]
    }
   ],
   "source": [
    "print(list(label_categories.category))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 836 different categorical variables describing the application types, I have to reduce the dimensionality of these categories. \n",
    "\n",
    "Is there a relationship between the category and the age?\n",
    "\n",
    "Is there a relationship between the category and the gender?\n",
    "\n",
    "If yes, which categories have the greatest correlationship to these two target variables, age and gender?\n",
    "\n",
    "Alas, I have too many categories to answer these questions. If more visuals are necessary through EDA, there are a few possibilities. I could plot the unknown data against the known data and see if there's a relationship between gender/age on that note. . .  I think I shouldn't have a problem visualizing during EDA and that it will be safe to skip this visualization. More categories may come or go and there's no need to mess it up; so to speak. \n",
    "\n",
    "This is a fine task for cluster analysis, perhaps it can reveal something that could provide similar answers. Perhaps not. I will want to retain these categorical values in their true form when I add them to the data table. I will want to create separate variable to hold my ML conversions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# App_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_labels = pd.read_csv('./data/app_labels.csv.zip', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "app_id      113211\n",
       "label_id       507\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_labels.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "548    56902\n",
       "405    53936\n",
       "794    49320\n",
       "795    48707\n",
       "704    45697\n",
       "714    19083\n",
       "713    11840\n",
       "854     9955\n",
       "710     9027\n",
       "711     8831\n",
       "Name: label_id, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_labels.label_id.value_counts().nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "app_id      0.0\n",
       "label_id    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_summary(app_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have more categories than I do 'in use' label ids."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>phone_brand</th>\n",
       "      <th>device_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-8890648629457979026</td>\n",
       "      <td>小米</td>\n",
       "      <td>红米</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1277779817574759137</td>\n",
       "      <td>小米</td>\n",
       "      <td>MI 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5137427614288105724</td>\n",
       "      <td>三星</td>\n",
       "      <td>Galaxy S4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3669464369358936369</td>\n",
       "      <td>SUGAR</td>\n",
       "      <td>时尚手机</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5019277647504317457</td>\n",
       "      <td>三星</td>\n",
       "      <td>Galaxy Note 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             device_id phone_brand   device_model\n",
       "0 -8890648629457979026          小米             红米\n",
       "1  1277779817574759137          小米           MI 2\n",
       "2  5137427614288105724          三星      Galaxy S4\n",
       "3  3669464369358936369       SUGAR           时尚手机\n",
       "4 -5019277647504317457          三星  Galaxy Note 2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phone = pd.read_csv('./data/phone_brand_device_model.csv.zip', compression='zip')\n",
    "phone.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device_id       0.0\n",
       "phone_brand     0.0\n",
       "device_model    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_summary(phone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device_id       186716\n",
       "phone_brand        131\n",
       "device_model      1599\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phone.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>device_model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phone_brand</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>魅族</th>\n",
       "      <td>11817</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>小米</th>\n",
       "      <td>43109</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPPO</th>\n",
       "      <td>14239</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HTC</th>\n",
       "      <td>2675</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>金立</th>\n",
       "      <td>2763</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vivo</th>\n",
       "      <td>14342</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>酷派</th>\n",
       "      <td>8382</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>华为</th>\n",
       "      <td>32466</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>三星</th>\n",
       "      <td>34191</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>联想</th>\n",
       "      <td>6752</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             device_id  device_model\n",
       "phone_brand                         \n",
       "魅族               11817            16\n",
       "小米               43109            26\n",
       "OPPO             14239            65\n",
       "HTC               2675            66\n",
       "金立                2763            67\n",
       "vivo             14342            80\n",
       "酷派                8382           140\n",
       "华为               32466           145\n",
       "三星               34191           163\n",
       "联想                6752           194"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phone.groupby(by='phone_brand').nunique().nlargest(10, columns='device_id').sort_values(by='device_model', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With over 100 brands and over 1,000 models, it is unlikely that I'll be able to conduct a visual analysis grouped by model or brand alone. With that said, it is unnecessary to convert the data to \"english\" at this point. The patterns are verily recognizable. \n",
    "\n",
    "I suspect that another cluster analysis against these features could also provide some insights into these demographics. Do I cluster on demographic and phones alone or do I cluster against the entire model? \n",
    "\n",
    "How about I look at the demographic (group) against the most popular brand by model? \n",
    "\n",
    "\n",
    "*notice:*\n",
    "\n",
    "I did look into getting these phone_brands and models translated. I ran into the following problems:\n",
    "1. The googletrans extension that was available on python ceased operation. There's a functional issue between the API and the authorization mechanism \n",
    "2. Importing a text or xlsx file into the documents portion of the google translate module return nil results.\n",
    "3. Using GoogleTranslate with GoogleSheets returned what looked like ingredients of a shopping list; not phone brand names. \n",
    "4. Using the translate feature on Excel provided no translations. In fact, Excel produces unrecognizable characters, even after experimenting with various encodings.\n",
    "5. A single copy paste of the characters into GoogleTranslate returns what looks like would be [reasonable results](https://translate.google.com/?sl=zh-CN&tl=es&text=%E8%81%94%E6%83%B3&op=translate). Translating each of these brands by hands is a bit much to ask; especially considering that they have a very small possibility of being put to use.  \n",
    "6. While Kaggle does have translations on a few of the models, I cannot see the point in constructing a [dictionary](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.translate.html) without a full translation available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a separate variable to hold the merge data.\n",
    "talkdata = events.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "talkdata['app_id'] = app_events.app_id\n",
    "talkdata['is_active'] = app_events.is_active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine phone with talkdata with the phone on device_id. The goal is to retain all event_ids; which are the uniquest thing. \n",
    "training_data = pd.merge(talkdata, phone.drop_duplicates(), on='device_id', how='left', indicator='phone_merge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the app_labels based on label_id. Keep all events. \n",
    "training_data = pd.merge(training_data, app_labels, right_on='app_id', left_on='app_id', how='left', indicator='app_merge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the categories on label_id. Keep all events.\n",
    "training_data = pd.merge(training_data, label_categories, right_on='label_id', left_on='label_id', how='left', indicator='cat_merge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the training data on device_id. Keep all training devices.\n",
    "training_data = pd.merge(training_data, gender_train, right_on='device_id', left_on='device_id', how='right', indicator='train_merge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "event_id        1215595\n",
       "device_id         74645\n",
       "timestamp        497663\n",
       "longitude          2914\n",
       "latitude           2707\n",
       "coordinates       32921\n",
       "app_id            12005\n",
       "is_active             2\n",
       "phone_brand          89\n",
       "device_model        926\n",
       "phone_merge           1\n",
       "label_id            475\n",
       "app_merge             1\n",
       "category            441\n",
       "cat_merge             1\n",
       "gender                2\n",
       "age                  85\n",
       "group                12\n",
       "train_merge           2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing -7808973 records\n"
     ]
    }
   ],
   "source": [
    "#no missing records. The device_ids are my training target variable. There should be no more or less of them. \n",
    "print(f'Missing {gender_train.device_id.count() - training_data.device_id.count()} records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['phone_merge', 'app_merge', 'cat_merge', 'train_merge'], dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_cols = training_data.columns[training_data.columns.str.contains('_merge')]\n",
    "merge_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "both          7832282\n",
       "right_only          0\n",
       "left_only           0\n",
       "Name: phone_merge, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.phone_merge.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "both          7832282\n",
       "right_only          0\n",
       "left_only           0\n",
       "Name: app_merge, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.app_merge.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "both          7832282\n",
       "right_only          0\n",
       "left_only           0\n",
       "Name: cat_merge, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.cat_merge.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "both          7832282\n",
       "right_only      51336\n",
       "left_only           0\n",
       "Name: train_merge, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.train_merge.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To retain or not to retain?\n",
    "\n",
    "Some of these events, labels, and categories have duplicate entries. How is this going to impact my results? Now I'm considering what the final product is going to look like. Am I going to dwell each time over duplicate event_ids or do I want to look at the devices, categories, time of day, etc. to determine the demographic?\n",
    "\n",
    "I'm going to keep these records. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_merge      1\n",
       "cat_merge        1\n",
       "phone_merge      1\n",
       "app_merge        1\n",
       "gender           2\n",
       "is_active        2\n",
       "group            6\n",
       "phone_brand      7\n",
       "longitude        9\n",
       "latitude         9\n",
       "coordinates      9\n",
       "age             10\n",
       "device_model    10\n",
       "device_id       10\n",
       "app_id          11\n",
       "timestamp       11\n",
       "event_id        11\n",
       "category        40\n",
       "label_id        44\n",
       "dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Looking at duplicate event_ids.\n",
    "training_data[training_data.event_id.isin(training_data.pivot_table(index=['event_id'], aggfunc='size'))].nunique().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_merge     0.000000\n",
       "device_id       0.000000\n",
       "age             0.000000\n",
       "gender          0.000000\n",
       "group           0.000000\n",
       "cat_merge       0.651173\n",
       "category        0.651173\n",
       "app_merge       0.651173\n",
       "label_id        0.651173\n",
       "phone_merge     0.651173\n",
       "event_id        0.651173\n",
       "is_active       0.651173\n",
       "app_id          0.651173\n",
       "coordinates     0.651173\n",
       "latitude        0.651173\n",
       "longitude       0.651173\n",
       "timestamp       0.651173\n",
       "phone_brand     0.651173\n",
       "device_model    0.651173\n",
       "dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I cannot predict the target variables that don't have any features associated with them.\n",
    "null_summary(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "event_id            0\n",
       "device_id       51336\n",
       "timestamp           0\n",
       "longitude           0\n",
       "latitude            0\n",
       "coordinates         0\n",
       "app_id              0\n",
       "is_active           0\n",
       "phone_brand         0\n",
       "device_model        0\n",
       "phone_merge         0\n",
       "label_id            0\n",
       "app_merge           0\n",
       "category            0\n",
       "cat_merge           0\n",
       "gender          51336\n",
       "age             51336\n",
       "group           51336\n",
       "train_merge     51336\n",
       "dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[training_data.event_id.isna()].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I can go ahead and drop the nulls.\n",
    "training_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "event_id        0.0\n",
       "age             0.0\n",
       "gender          0.0\n",
       "cat_merge       0.0\n",
       "category        0.0\n",
       "app_merge       0.0\n",
       "label_id        0.0\n",
       "phone_merge     0.0\n",
       "group           0.0\n",
       "device_model    0.0\n",
       "is_active       0.0\n",
       "app_id          0.0\n",
       "coordinates     0.0\n",
       "latitude        0.0\n",
       "longitude       0.0\n",
       "timestamp       0.0\n",
       "device_id       0.0\n",
       "phone_brand     0.0\n",
       "train_merge     0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#All clean. I'm good on my training_data sets.\n",
    "null_summary(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#there are no test devices in my training dataset. \n",
    "training_data.device_id[training_data.device_id.isin(gender_test.device_id)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove unnecessary columns \n",
    "id_cols = training_data.columns[training_data.columns.str.contains('_id')]\n",
    "drop_cols = list(merge_cols.values) + list(id_cols.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>is_active</th>\n",
       "      <th>phone_brand</th>\n",
       "      <th>device_model</th>\n",
       "      <th>category</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-05-01 14:23:37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>小米</td>\n",
       "      <td>MI 2</td>\n",
       "      <td>1 free</td>\n",
       "      <td>M</td>\n",
       "      <td>35</td>\n",
       "      <td>M32-38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-05-01 14:23:37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>小米</td>\n",
       "      <td>MI 2</td>\n",
       "      <td>Cozy 1</td>\n",
       "      <td>M</td>\n",
       "      <td>35</td>\n",
       "      <td>M32-38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-05-01 14:23:37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>小米</td>\n",
       "      <td>MI 2</td>\n",
       "      <td>Industry tag</td>\n",
       "      <td>M</td>\n",
       "      <td>35</td>\n",
       "      <td>M32-38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-05-01 14:23:37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>小米</td>\n",
       "      <td>MI 2</td>\n",
       "      <td>Property Industry 2.0</td>\n",
       "      <td>M</td>\n",
       "      <td>35</td>\n",
       "      <td>M32-38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016-05-01 14:23:37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>小米</td>\n",
       "      <td>MI 2</td>\n",
       "      <td>music</td>\n",
       "      <td>M</td>\n",
       "      <td>35</td>\n",
       "      <td>M32-38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp  longitude  latitude coordinates  is_active  \\\n",
       "2  2016-05-01 14:23:37        0.0       0.0  (0.0, 0.0)        1.0   \n",
       "3  2016-05-01 14:23:37        0.0       0.0  (0.0, 0.0)        1.0   \n",
       "4  2016-05-01 14:23:37        0.0       0.0  (0.0, 0.0)        1.0   \n",
       "5  2016-05-01 14:23:37        0.0       0.0  (0.0, 0.0)        1.0   \n",
       "6  2016-05-01 14:23:37        0.0       0.0  (0.0, 0.0)        1.0   \n",
       "\n",
       "  phone_brand device_model               category gender  age   group  \n",
       "2          小米         MI 2                 1 free      M   35  M32-38  \n",
       "3          小米         MI 2                 Cozy 1      M   35  M32-38  \n",
       "4          小米         MI 2           Industry tag      M   35  M32-38  \n",
       "5          小米         MI 2  Property Industry 2.0      M   35  M32-38  \n",
       "6          小米         MI 2                  music      M   35  M32-38  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The datatable name is talkdata\n",
    "talkdata = training_data.drop(columns=drop_cols)\n",
    "talkdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export to talkdata.csv.\n",
    "talkdata.to_csv('./data/talkdata.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "I have a lot of features. Most of them are categorical. \n",
    "\n",
    "I want to reduce the dimensionality of this categorical feature set. I have read many things. One of which is that PCA and T-SNE are not good enough for dimensionality reduction.\n",
    "\n",
    "[SciKit Learn](https://scikit-learn.org/stable/modules/unsupervised_reduction.html) suggests otherwise. I want to implement PCA, t-SNE, and *if possible* [feature agglomeration](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.FeatureAgglomeration.html#sklearn.cluster.FeatureAgglomeration) to reduce these categorical features using scikit learn. The selectkbest transformation is also available. It offers a few extra paramaters such as f_classif and chi2 algorithms scoring which would work well in a pipeline.   \n",
    "\n",
    "Explained variance is important and there are a number of parameters that are available with each of these choices. I will be using the pipeline option with gridsearch cv to find the optimal parameters for feature reduction with this dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
